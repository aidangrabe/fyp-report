%% IMPLEMENTATION

\section{Language Choice}
Java was the language used in implementing the applications outlined in the
previous chapters. Android applications can be created using Java, C or C++.
Since each application running on an Android device is executed in a Java
Virtual Machine (JVM), Java is the primary development language used on the
platform.\\
C or C++ could also be used thanks to the Android NDK, but as the official
documentation suggests\footnote{NDK documentation - http://goo.gl/OykZpe},
should only be used for very specific, CPU-intensive tasks and one should not
use the NDK because they prefer writing applications in C/C++.

In addition to these lower-level languages, many other languages can be used
thanks to third-party transpilers such as PhoneGap (JavaScript), Apportable
(Objective-C/Swift), Titanium (JavaScript) etc.\\
These tools allow developers to write code in different languages and either
run them in a \texttt{WebView} using JavaScript and HTML5 or transpiles the
source code into Java and compiles as if the developer had used Java in the
first place.

\section{Development Tools}

\subsection{IDE}
When it comes to Android Development, two main IDEs stand out:
\begin{enumerate}
\item Eclipse\\
    Eclipse was the original official Android development environment and is
    still used by many developers. It uses a plugin called ADT
    (Android Development Tools) to interact with ADB and manages SDKs etc.
\item Android Studio\\
    Android Studio is currently the official IDE for Android and comes with
    many improvements over Eclipse. It is built on top of the popular IntelliJ
    IDE, and is tailored specifically for Android development. This allows it
    to have specific Android tools and functionality 'baked in', thus not
    requiring any plugins to begin development.\\
    Android Studio also comes with built-in functionality for the Gradle build
    system, allowing for easier dependency management and a more sophisticated
    build environment.
\end{enumerate}

With Android's new Gradle build system, it is possible to use no more than a
text editor and the Android build tools from the command line to compile and
run an application. However, for building interfaces and the editing tools
an IDE can offer, Android Studio was used.

\subsection{Version Control}
Android Studio has built-in support for the most popular version control
systems. Git was chosen due to the sheer volume of libraries available on Github
and Google's sample projects from the Android documentation site also use it.

%% Communication

\section{Android Wear Communication}

This section details how an Android device communicates with its Android Wear
counterpart using Bluetooth and the Android Wear APIs. Communication was a
fundamental part of the project and is used to send messages, commands or entire
objects from handheld to smartwatch and vice-versa.

\subsection{Pre-requisites}
In order for a smartwatch application to communicate with its counterpart
handheld application, a few conditions must be met.

\begin{enumerate}
\item Android Wear Companion App\\
    As mentioned in previous chapters, the official Android Wear Companion App
    must be installed, and the wearable must connected and paired with the
    handheld through this app.
\item Package name
    Both the wearable and the handheld applications must use the same package
    name in their \texttt{AndroidManifest.xml} files. The APIs will not work
    correctly and communication will not occur between the applications if one
    of the package names is different.
\end{enumerate}

\subsection{Communication Types}
With Android Wear there are two main types of communication:
\begin{enumerate}
\item Messages\\
    Messages are blobs of data limited in size to 100KB, which are sent from one
    device to another. The destination of the message must be known when
    sending.\\
    Messages are useful for RPC or a client-server messaging protocol.
\item DataItems
    DataItems are blobs of data which when created are automatically synced
    across the Android Wear network and replicated on all connected nodes.
    DataItems are useful for ensuring data is kept the same on both handheld and
    wearable.
\end{enumerate}

All communication is handled by the system. The API for doing this is all dealt
with by the \texttt{GoogleApiClient}. This API client connects to Google Play
Services and allows for interaction with Google services, such as Android Wear,
Play Games, Google Drive etc.\\
As a result, multiple APIs can be accessed via a single
\texttt{GoogleApiClient}, however, Google recommend using a single
\texttt{GoogleApiClient} instance for dealing solely with Android Wear
communications. This prevents failure callbacks for users that don't have a
wearable device if they are trying to access another service.

\begin{lstlisting}[language=Java]
GoogleApiClient mGoogleApiClient = new GoogleApiClient.Builder()
        .addApi(Wearable.API)
        .addConnectionCallbacks(mConnectionCallbacks)
        .addOnConnectionFailedListener(
            mOnConnectionFailedListener)
        .build();
\end{lstlisting}

Here we create a GoogleApiClient and tell it which API to connect to, which in
this case is the Wearable API. We also set its connection callbacks and
listeners.
This allows us to get notified of connection events such as when the device is
connected, suspended etc.

\texttt{mConnectionCallbacks} and \texttt{mOnConnectionFailedListener} might
look something like the following:

\begin{lstlisting}[language=Java]
mConnectionCallbacks = new ConnectionCallbacks() {
    @Override
    public void onConnected(Bundle connectionHint) {

        // device has been connected succefully to the
        // Wearable/Handheld

    }

    @Override
    public void onConnectionSuspended(int cause) {

        // the connection has been suspended. Device out
        // of range, or unavailable

    }
}

mOnConnectionFailedListener =
        new OnConnectionFailedListener() {
    @Override
    public void onConnectionFailed(ConnectionResult result) {
        
        // the connection failed to initialize

    }
}

\end{lstlisting}

In order to use the \texttt{GoogleApiClient}, it must be connected to Google
Services. Here is how we achieve this with the Android Activity lifecycle:

\begin{lstlisting}

public class MyActivity extends Activity {

    ...

    @Override
    public void onResume() {
        super.onResume();
        mGoogleApiClient.connect();
    }

    @Override
    public void onPause() {
        super.onPause();
        mGoogleApiClient.disconnect();
    }

    ...

}

\end{lstlisting}


% MESSAGE APPI
\subsection{Message API}

Once the \texttt{GoogleApiClient} is connected, it can be used to send messages
and/or \texttt{DataItem}s. In order to send a message we need the following
information:

\begin{enumerate}
\item A connected \texttt{GoogleApiClient}.
\item A \texttt{Node} to send the message to.
\item A path for the message so the receiving application can decide which
    action to apply.
\item A payload
\end{enumerate}

All paths on Android Wear communications are relative to a base URI which Wear
uses to communicate. These URIs are of the form:
\texttt{wear://<node-id>/<path>}

\begin{lstlisting}[language=Java]
Wearable.MessageApi.sendMessage(
        mGoogleApiClient,
        nodeId,         // String : the id of the receiving Node
        "/start/music", // String : the path of the message

        // byte[] : the payload of the message
        "song-123".getBytes()
);
\end{lstlisting}

On the receiving end, when a message is received, we can check whether it's the
message we are interested in by checking the path:

\begin{lstlisting}[language=Java]
...
if (path.equals("/start/music") {
    // open music player
}
\end{lstlisting}

Using this technique we can send multiple different messages and perform
different actions on the handheld based on the path of the messages.

\subsubsection{Receiving Messages}
Sending messages from the handheld to the watch or vice-versa is only useful if
the other side is listening for these messages. In order to perform actions or
respond received messages, the device must register itself with the Android Wear
API and implement a callback method for when a message is received.\\
In order to start receiving messages from the counter-part application, the
application must register itself as a listener to the \texttt{MessageApi}:

\begin{lstlisting}[language=Java]

@Override
public void onResume() {
    super.onResume();
    // add the listener
    Wearable.MessageApi.addListener(mGoogleApiClient, mListener);
}

...

@Override
public void onPause() {
    super.onPause();
    // remove the listener
    Wearable.MessageApi.removeListener(mGoogleApiClient, mListener);
}
\end{lstlisting}

The listener for receiving message events looks like this:

\begin{lstlisting}[language=Java]
@Override
public void onMessageReceived(MessageEvent messageEvent) {

    // get the path of this message's URI
    String path = messageEvent.getPath();

    // perform an action based on the path
    if (path.equals("/start/music")) {
        // start the music application
        Intent intent = new Intent(this, MusicActivity.class);
        startActivity(intent);
    }

}
\end{lstlisting}

Using this send-respond architecture, a client-server model can be created
whereby the wearable can request data from the handheld using a custom
protocol, and the handheld can reply with the requested data.\\
It also enables using the wearable as a remote to start activities or trigger
actions on the handlheld, such as launching a compose new email activity or
starting/stopping music playback.

%% DATA API
\subsection{Data API}
Previously we discussed sending messages and performing actions upon receiving
them. Android Wear provides another form of communication allowing developers
to synchronize data across both the handheld and wearable. Whenever the data is
updated on one size, an event is triggered on the other notifying it of the
change.

This is useful for sending images, or keeping data consistent across both
devices. For example, the handheld could retrieve contact data from it's
database using SQLite and store it in the wearable \texttt{DataApi}. Provided
the wearable has registered itself for receiving data changes, the data would
then present itself to the wearable where it could be displayed or stored in
it's own SQLite database.

\subsubsection{Inserting DataItems to the Data Layer}
In order to insert something into the data layer, we must first create a
\texttt{PutDataRequest} which is very similar to a java \texttt{Map} but that
deals with byte arrays. To make things simpler, we can use a
\texttt{PutDataMapRequest}, which behaves more like a traditional \texttt{Map}
where we can store key-value pairs of primitive types.

As with all communication on Android Wear, we must also specify a path for this
data's URI. We can then hand this \texttt{PutDataMapRequest} off to the system
for synchronization.

\begin{lstlisting}[language=Java]
// create the PutDataMapRequest with a given path
PutDataMapRequest putDataMapRequest =
        PutDataMapRequest.create("/settings");

// get a more traditional map from the PutDataMapRequest
DataMap dataMap = putDataMapRequest.getDataMap();

// fill the map with some primitive data
dataMap.putString("color", "#FFAAFF");
dataMap.putFloat("rating", 4.5f);
dataMap.putInt("refresh_interval", 20);

// convert our traditional map back to a byte[] map
PutDataRequest putDataRequest = putDataMapRequest
        .asPutDataRequest();

// hand the request off to the system to put the map
// in the data layer
Wearable.DataApi.putDataItem(mGoogleApiClient, dataMap);
\end{lstlisting}

In the code above, we created a map containing some basic settings and put the
map into the data layer. This means the data will be accessible from either
device. If the handheld or wearable are not connected or out of range, the
system will queue the request and perform when possible. This does not have to
be handled by the developer.

\subsubsection{Retrieving DataItems from the Data Layer}
Retrieving \texttt{DataItem}s from the data layer is slightly different. If we
know the path of the data we want to retrieve, we can use

\begin{lstlisting}[language=Java]
Wearable.DataApi.getDataItem(mGoogleApiClient, uri);
\end{lstlisting}

where \texttt{uri} is the \texttt{URI} of the item we want to retrieve. This
involves building the URI manually which can be cumbersome and erroneous. A
simpler way of retrieving \texttt{DataItem}s is by fetching all items and
filtering them by path as shown below.

\begin{lstlisting}[language=Java]
DataItemBuffer dataItemBuffer = Wearable.DataApi
        .getDataItems(mGoogleApiClient)
        .await();

for (DataItem dataItem : dataItemBuffer) {
    String path = dataItem.getUri().getPath();

    // check we are using the correct 
    if (path.equals("/settings")) {
        // create a DataMapItem from the given DataItem
        // so we can access our map
        DataMapItem dataMapItem = DataMapItem
                .fromDataItem(item);
        DataMap dataMap = dataMapItem.getDataMap();

        // get the settings back out of the map
        String color = dataMap.getString("color");
        Float rating = dataMap.getFloat("rating");
        int refreshInterval= dataMap.getInt("refresh_interval");
    } else if (path.equals("/other-data")) {
        ...
    }
}

// make sure to release the buffer to prevent leaking memory
dataItemBuffer.release();
\end{lstlisting}

%% Data layer events

\subsubsection{Data Layer Events}

In order to be able to synchronize data across the handheld and wearable
devices, listeners must be created and added to the \texttt{DataApi}. Then, 
whenever \texttt{putDataItem()} is called, the listeners on both sides of the
communications will be notified.

For example, when the wearable application first starts, it may call
\texttt{getDataItems()} to get all the \texttt{DataItem}s currently stored in
the data layer and store the relevant information in memory. It might then add
a listener to the \texttt{DataApi} in order to watch changes to this data and
update its internal data structures for that data.

\begin{lstlisting}[language=Java]

@Override
public void onResume() {
    super.onResume();
    Wearable.DataApi.addListener( mGoogleApiClient,
            mListener);
}

@Override
public void onPause() {
    super.onPause();
    Wearable.DataApi.removeListener( mGoogleApiClient,
            mListener);
}

\end{lstlisting}

The above code demonstrates how to add a listener for data layer events to an
\texttt{Activity}. When the \texttt{Activity} is suspended to the background
we genereally don't want to interact with the events. A \texttt{Service} can be
used to interact with data layer events when the application is not in the
foreground. This will be explained in the next section.\\
Below is what \texttt{mListener} might look like for handling data layer events

\begin{lstlisting}[language=Java]

mListener = new DataApi.DataListener() {

    @Override
    public void onDataChanged(DataEventBuffer dataEventBuffer) {
        
        // there may be multiple events handled at once
        for (DataEvent dataEvent : dataEventBuffer) {

            // get the DataItem from the event
            DataItem dataItem = dataEvent.getDataItem();
            String path = dataItem.getUri().getPath();

            // ignore items that we are not interested in
            if (! path.equals("/settings") {
                continue;
            }

            // we only want to perform actions on data that
            // has changed
            if (event.getType() == DataEvent.TYPE_CHANGED) {
                DataMap dataMap = DataMapItem
                        .fromDataItem(dataItem)
                        .getDataMap();

                // get the new settings from the map
                String newColor = dataMap.getString("color");
                Float newRating = dataMap.getFloat("rating");
                int newRefresh = dataMap
                        .getInt("refresh_interval");
            }
        }

    }

};

\end{lstlisting}

%% WearableListenerService

\subsection{WearableListenerService}

In this section communicating with wearables from a \texttt{Service} will be
discussed. Android Wear APIs come with a special \texttt{Service} designed
specifically for communicating with wearables:
\texttt{WearableListenerService}.

In order to use \texttt{WearableListenerService}, it must be extended by a
custom \texttt{Service}. Just like any regular Android \texttt{Service}, it must
first be declared in the \texttt{AndroidManifest.xml} file but with a special
\texttt{intent-filter}:

\begin{lstlisting}[language=XML]

<service android:name=".DataLayerListenerService">
    <intent-filter>
        <action android:name=
            "com.google.android.gms.wearable.BIND_LISTENER" />
    </intent-filter>
</service>

\end{lstlisting}

Unlike a normal Android \texttt{Service}, it must not be started or stopped.
The system handles this.\\
This \texttt{Service} must extend \texttt{WearableListenerService} and
override it's communication methods. In order to listen for communication
events, a \texttt{GoogleApiClient} must be created and the listeners must be
attached as described in previous sections.

\begin{lstlisting}[language=Java]

public class DataLayerListenerService extends
        WearableListenerService {
    
    @Override
    public void onCreate() {
        super.onCreate();

        mGoogleApiClient = new GoogleApiClient.Builder()
                ...
                .build();

        // since we are running in a Service, we can call
        // a blocking method. Calling this on the main thread
        // of an Activity would cause an error and the async
        // mGoogleApiClient.connect() would have to be used
        // instead
        mGoogleApiClient.blockingConnect();

        // attach the listeners
        Wearable.MessageApi.addListener(mGoogleApiClient, this);
        Wearable.DataApi.addListener(mGoogleApiClient, this);

    }

    @Override
    public void onDestroy() {
        super.onDestroy();

        // remove the listeners
        Wearable.MessageApi.removeListener(mGoogleApiClient, this);
        Wearable.DataApi.removeListener(mGoogleApiClient, this);

        // ensure we disconnect from the Wearable API
        mGoogleApiClient.disconnect();
    }

    @Override
    public void onPeerConnected(Node peer) {
        super.onPeerConnected(peer);

        // called when the wearable and handheld have been
        // connected
    }

    @Override
    public void onDataChanged(DataEventBuffer dataEvents) {
        // code to deal with changed or delete data events
    }

    @Override
    public void onMessageReceived(MessageEvent messageEvent) {
        // code to run when message received
    }

}

\end{lstlisting}

This type of \texttt{Service} allows us to listen for communication events even
when the application is not in the foreground. This is quite a common case as
it is quite rare that a user would have the application open on both the
wearable and the handheld at the same time. In the Student Application discussed
in this report, a \texttt{WearableListenerService} is created on handheld and
acts as a server to the wearable. The \texttt{Service} could just as easily have
been created on the wearable, or on both.


%% ASSETS

\subsection{Syncing Assets}
Up to this point, syncing data and sending messages have been limited to 100KB
in payload. In order to send data of larger size such as images or audio files,
\texttt{Asset}s must be used. \texttt{Asset}s are attached to
\texttt{DataItem}s and are stored and retrieved in a similar way to any other
data stored in a \texttt{DataItem}.

\begin{lstlisting}[language=Java]

// get the Bitmap to send from the device's resources
Bitmap bitmap = BitmapFactory.decodeResource(
        getResources(), R.drawable.ic_launcher);

// here we need to convert the Bitmap into an Asset
// an Asset can be created from a byte array, so we must
// get the byte array from the Bitmap
ByteArrayOutputStream byteStream =
        new ByteArrayOutputStream();
bitmap.compress(Bitmap.CompressFormat.PNG, 100, byteStream);
Asset asset = Asset.createFromBytes(byteStream.toByteArray());


// here we create a PutDataMapRequest just like we did
// for putting primitive values into the data layer
PutDataMapRequest putDataMapRequest =
        PutDataMapRequest.create("/image");

// get the DataMap for this PutDataMapRequest
DataMap dataMap = putDataMapRequest.getDataMap();

// add the Asset to the DataMap
dataMap.putAsset("icon", asset);

// sync the DataMap containing the Asset into the data layer
Wearable.DataApi.putDataItem(mGoogleApiClient,
        dataMap.asPutDataRequest());

\end{lstlisting}

In order to receive the Asset on the other side of the communication, we must
implement the \texttt{DataApi.DataListener} and check for the event in
\texttt{onDataChanged()}.

\begin{lstlisting}[language=Java]

...

@Override
public void onDataChanged(DataEventBuffer dataEvents) {

    for (DataEvent dataEvent : dataEvents) {
        DataItem dataItem = dataEvent.getDataItem();
        String path = dataItem.getUri().getPath();

        if (path.equals("/image")) {
            DataMap dataMap = DataMapItem
                    .fromDataItem(dataItem)
                    .getDataMap();

            // retrieve the Asset from the DataMap
            Asset asset = dataMap.getAsset("icon");
            onAssetReceived(asset);

        }
    }

}

private void onAssetReceived(Asset asset) {

    // Assets have unique file descriptors on the device
    // get the file descriptor for the given Asset
    // this method is called asynchronously, to get an
    // immediate repsonse, await() could be used, but only
    // in a background thread
    Wearable.DataApi.getFdForAsset(mGoogleApiClient, asset)
            .setResultCallback(new
                ResultCallback<DataApi.GetFdForAssetResult>()
                    {

        @Override
        public void onResult(DataApi.GetFdForAssetResult
                getFdForAssetResult) {

            // re-construct the Bitmap from the file
            InputStream assetInputStream =
                    getFdForAssetResult.getInputStream();
            Bitmap mapBitmap = BitmapFactory
                        .decodeStream(assetInputStream);

            // do something with the received Bitmap

        }

    });
}

...

\end{lstlisting}


%% SERIALIZATION

\subsection{Object Serialization}

When communicating between handheld and wearable, a common use case might
require a Java object to be used on both devices, for example a calendar event.
In order to achieve this, the object must be broken down into it's primitive
data, transfered as an array of bytes and reconstructed on the other side of
the connection. Android has built-in interfaces for this, namely the
\texttt{Parcelable} interface.

When an object implements \texttt{Parcelable} it describes itself in terms of
it's primitive data such as \texttt{Integer}s, \texttt{Float}s and
\texttt{String}s. This data can then be written to a \texttt{Parcel} object and
"marshalled" into a byte array. \texttt{Parcelable} objects can be nested within
other \texttt{Parcelable} objects. The \texttt{Parcelable.Creator<T>} interface
specifies how an object of type \texttt{T} should be recreated from a
\texttt{Parcel}.

For Android Wear, \texttt{DataMap}s could also be used instead of
\texttt{Parcel}s, but since \texttt{Parcel}s are used frequently in Android
development, such as passing an object between Activities, \texttt{Parcel}s
may be more versatile for re-use.

Below is an example of a simple object which implements \texttt{Parcelable}

\begin{lstlisting}[language=Java]

public class CalendarEvent implements Parcelable {

    private String title;
    private int numAttendees;
    private Date date;

    // nested Parcelable oject
    private Parcelable myObject;

    ...

    // Describe the kinds of special objects contained in
    // this Parcelable's marshalled representation
    @Override
    public int describeContents() {
        return 0;
    }

    @Override
    public void writeToParcel(Parcel out, int flags) {
        out.writeString(title);
        out.writeInt(numAttendees);
        out.writeLong(date.getTime());
        out.writeParcelable(myObject);
    }

    // the object that will handle reconstructing the event
    public static final Creator<CalendarEvent> CREATOR =
            new Creator<CalendarEvent>() {

        @Override
        public CalendarEvent createFromParcel(Parcel source) {
            // reconstruct the CalendarEvent from the given
            // Parcel
            CalendarEvent event = new CalendarEvent();
            event.setTitle(source.readString());
            event.setNumAttendees(source.readInt());
            event.setDate(new Date(source.readLong()));

            // reconstruct the nested Parcelable object
            event.setMyObject(source.readParcelable(
                MyObject.class.getClassLoader()));
            return event;
        }

        @Override
        public CalendarEvent[] newArray(int size) {
            // create a new CalendarEvent array
            return new CalendarEvent[size];
        }

    };

}

\end{lstlisting}

Now when an instance of the \texttt{CalendarEvent} class is created, it can
be put into a parcel and marshalled as follows:

\begin{lstlisting}[language=Java]

// get a free Parcel instance
Parcel parcel = Parcel.obtain();
CalendarEvent event = new CalendarEvent();

// write the event into the Parcel using the methods
// implemented above
event.writeToParcel(parcel, 0);

// set the data pointer back to the start ready for reading
parcel.setDataPosition(0);

// to then be able to transfer the Parcel with Android Wear
DataMap dataMap = ...
String key = "cal-event";
dataMap.putByteArray(key, parcel.marshall());

// the DataMap can then be synced using the data api or
// message apis

// recycle the Parcel when it is no longer needed
parcel.recycle();

\end{lstlisting}

In order to read the serialized \texttt{Parcel} on the other side of the
connection, a \texttt{Parcel} must be obtained, and it must unmarshall the byte
array from the \texttt{DataMap}. Using the \texttt{CREATOR} instance created
above, the \texttt{CalendarEvent} can be reconstructed from the \texttt{Parcel}.

\begin{lstlisting}[language=Java]

DataMap dataMap = ... // get the DataMap from Android Wear

byte[] byteArray = dataMap.getByteArray(key);

Parcel parcel = Parcel.obtain();

// unmarshall the byte array into the new Parcel
parcel.unmarshall(byteArray, 0, byteArray.length);

// reset the data pointer to the start for reading
parcel.setDataPosition(0);

// read the parcel data, and create a CalendarEvent
CalendarEvent event = creator.createFromParcel(parcel);

parcel.recycle();

\end{lstlisting}

Of course if the code permits, a \texttt{DataMap} could be used directly instead
of a \texttt{Parcel}, but using a \texttt{Parcel} may allow the developer to
serialize the object for saving to disk or passing the object between processes
or activities.


%% Communication Threads
\subsection{Communication Threads}

The Android Wear communication APIs described in previous sections are all
carried asynchronously with callback methods called in background threads.
The APIs return a \texttt{PendingResult<T>} instance with the relevant
results from the API call.

Android does not allow updating of the user interface from a thread other than
the main UI thread. In order to update the UI on a result from an Android Wear
API call, a \texttt{Handler} must be used to post the UI code to the main UI
thread for execution. This can be done as follows:

\begin{lstlisting}[language=Java]

PendingResult<MessageApi.SendMessageResult> result;
result = Wearable.MessageApi.sendMessage(
        mGoogleApiClient, nodeId, path, messageBytes);

result.setResultCallback(new ResultCallback
        <MessageApi.SendMessageResult>() {
    @Override
    public void onResult(MessageApi.SendMessageResult result) {
        // called on a background thread when the message
        // has been sent
        onMessageResult(result);
    }
});

private void onMessageResult(final String result) {

    // perform non-UI logic here
    doSomething();

    // perform UI logic here
    (new Handler(Looper.getMainLooper())).post(new Runnable() {
        @Override
        public void run() {
            mTextView.setText("Result: "
                + result.getStatus().toString());
        }
    });

}

\end{lstlisting}

In order to run the UI logic on the main thread, a \texttt{Runnable} is posted
to the main \texttt{Handler} and gets scheduled for processing.

If an Android Wear comunications API method is called from a thread that is
already running in the background, there is no need to use callbacks at all.
\texttt{PendingResult}s have an \texttt{await()} method which blocks execution
until the result is ready for processing. If multiple API calls need to be made
in immediate succession, it might make sense to run them all on a background
thread and just use one callback for the overall result. This can be achieved
using an \texttt{AsyncTask}. The \texttt{await()} method cannot be run on the
main thread, if it is, the application will crash and throw an exception.

\begin{lstlisting}[language=Java]

(new AsyncTask<Void, Void, Void>() {
    
    @Override
    protected Void doInBackground(Void... params) {
        // make API calls
        MessageApi.SendMessageResult result;
        result = Wearable.MessageApi.sendMessage(
            mGoogleApiClient, nodeId, path, messageBytes).await();
        if (result.getStatus().isSuccess() {
            // make another API call
        }
    }

    @Override
    protected void onPostExecute(Void aVoid) {
        // execute callback method here
        // this method runs on the UI thread
    }

}).execute();

\end{lstlisting}


%% SENSORS

\section{Sensors}

Sensors allow devices to read data from the outside world. Applications can use
sensor data to monitor real-time data and perform actions on it, or present it
to the user in a more digestible way.

Android supports measuring raw data from many different types of sensors. The
availability of sensors depends on the device and version of Android it is
running. Android Wear is no different. Android Wear allows for the same APIs
to be used in detecting and measuring data from built-in sensors.

Android Wear provides the user with access to sensors a regular Android device
might not have access to. This project was carried out and tested on a
Samsung Gear Live device. On this device, there is a heart-rate monitor which
can measure the rate at which the heart beats by using a bright LED on the back
of the watch to illuminate the top of your wrist and measure the rate of the
pulsing of the blood.\\
This method requires the wearer to be completely still and that the LED be
completely clean to give an accurate reading. Even when these conditions are
met, there is still a certain skepticism as to how accurate this type of
monitor really is.

In any case, Android Wear provides the same APIs for accessing sensors on a
wearable as those used to achieve the same on a handset. The
\texttt{SensorManager} is used to query the availability of different
\texttt{Sensor}s at runtime. A \texttt{Sensor} object then provides methods
allowing you to discover the capabilities and retrieve information regarding
the underlying sensor such as resolution, maximum range.\\
The \texttt{SensorManager} also allows us to attach listeners to each sensor
to listen for events related to the sensor, such as when the accuracy of the
sensor changes or when the values of the sensor are updated or changed by the
underlying hardware for the sensor.

The below code listing demonstrates how one might sense heart-rate data from
a wearable device. The code could also be run on a handset device with no
errors, but would not return any data unless it was equipped with a heart-rate
monitor.

\begin{lstlisting}[language=Java]

public class HeartRateActivity extends Activity
        implements SensorEventListener {

    // the SensorManager is used to retrieve the heart-rate
    // sensor
    private SensorManager mSensorManager;

    // this is the heart-rate sensor itself which will be
    // used to measure the raw data
    private Sensor mHeartSensor;

    @Override
    public void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        
        mSensorManager = (SensorManager)
                getSystemService(SENSOR_SERVICE);

        // ask the SensorManager for a heart-rate sensor
        // if there is no heart rate sensor present, this
        // will return null
        mHeartSensor = mSensorManager
                .getDefaultSensor(Sensor.TYPE_HEART_RATE);

    }

    @Override
    public void onResume() {
        // start listening for events on the heart sensor
        mSensorManager.registerListener(this, mHeartSensor,
                SensorManager.SENSOR_DELAY_NORMAL);
    }

    @Override
    public void onPause() {
        mSensorManager.unregisterListener(this,
            mHeartSensor);
    }



    @Override
    public final void onAccuracyChanged(Sensor sensor,
            int accuracy) {
        // called when the accuracy of the sensor has changed
    }

    @Override
    public final void onSensorChanged(
            SensorEvent event) {
        // event.values can be more than one
        // eg. accelerometer returns 3 values
        float heartRate = event.values[0];

        Log.d("HeartRateActivity", String.format(
            "Received heart rate %.0f", heartRate));
    }

}

\end{lstlisting}

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{heart-rate-monitor-activity.png}
    \caption{Activity monitoring heart-rate}
    \label{fig:awesome_image}
\end{figure}

If a higher degree of accuracy is needed, a higher sample rate can be specified
for measuring the raw sensor data. It should be noted however, that selecting a
higher sampling rate can consume more power than a slower sampling rate. As a
result it is recommended to use a high sampling rate only when necessary.\\
In the above example the default sampling rate of
\texttt{SensorManager.SENSOR\_DELAY\_NORMAL} was used. The available sampling
rates are listed below:
\begin{enumerate}
\item SENSOR\_DELAY\_NORMAL (default) - 200ms
\item SENSOR\_DELAY\_UI - 60ms
\item SENSOR\_DELAY\_GAME - 20ms
\item SENSOR\_DELAY\_FASTEST 0ms
\end{enumerate}

When attempting to listen on a sensor that is not available, the system should
continue running. When an application requires the use of a specific sensor,
that is to say the application needs it to function, it should declare so in
it's \texttt{AndroidManifest.xml} file. eg.

\begin{lstlisting}[language=XML]

<uses-feature
    android:name="android.hardware.sensor.accelerometer"
    android:required="true" />

\end{lstlisting}

Note that this is not necessary, but would help filter capable devices on the 
Google Play Store if submitted.


%% Gestures

\clearpage
\section{Gestures}

Android Wear smartwatches come with accelerometers and gyroscopes, this means
the devices can distinguish their orientation in 3d space. Using these sensors
we can determine movement or gestures by the user, just like on a smartphone.
Smartwatches have the added benefit of being located on a user's wrist, the
perfect spot for detecting gestures created by the user's arm. One of the goals
of this project was to be able to detect simple linear gestures ie. when
the user thrusts their arm up, down, left, right, forwards or backwards.

Listening to the accelerometer data is the same as listening to any other sensor
on the device which is explained in the previous section. However, detecting 3d
gestures is not straight forward, and very few libraries exist for detecting
such gestures. An accelerometer measures the acceleration on 3 different axes: 
x, y and z as shown in figure \ref{fig:accelerometer_axes}. Gestures in this
project are detected by waiting for a value of x, y or z from the accelerometer
to exceed a certain threshold. Since the values of x, y and z can be negative
or positive, some calculations must be done first in order to determine on
which axis the gesture occurred.

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{watch-axes.png}
    \caption{Three axes of the accelerometer}
    \label{fig:accelerometer_axes}
\end{figure}

\begin{lstlisting}[language=Java]

double, absX, absY, absZ, biggest;
absX = Math.abs(x);
absY = Math.abs(y);
absZ = Math.abs(z);

// get the largest value
biggest = Math.max(Math.max(absX, absY), absZ);

// see if the largest value is above the minimum threshold
if (biggest > GESTURE_THRESHOLD) {
    // do gesture detection
}

\end{lstlisting}

The above method works fairly well for ignoring small movements and accidentally
triggering a gesture, but if the user does a fast movement to trigger a gesture
in one direction, an equal but opposite gesture will be triggered almost
immediately after as the user's hand come to a stop. In order to ignore this
second stopping gesture, a delay is used after registering the first gesture, so
no gestures can be detected until after this delay. This prevents the pair of
gestures from being detected together. Care must be taken to use a threshold
high enough so that the second gesture is ignored, but low enough so that a
second unique gesture is not accidentally missed as well. In tests, 700ms to
1 second seemed to be an adequate delay.

Once the threshold as been exceeded, we know a gesture has occurred, the next
step is to figure out which axis the gesture occurred on. This can be checked
using a simple multi-arm conditional statement.

\begin{lstlisting}[language=Java]

String gestureLessThan, gestureGreaterThan;
double val = x;

// check which axis the gesture occurred on
if (absY == biggest) {
    gestureLessThan     = "DOWN";
    gestureGreaterThan  = "UP";
    val = y;
} else if (absZ == biggest) {
    gestureLessThan     = "FORWARDS";
    gestureGreaterThan  = "BACKWARDS";
    val = z;
} else {
    gestureLessThan     = "LEFT";
    gestureGreaterThan  = "RIGHT";
}

// decide whether the movement was positive or negative
String gesture = val > 0 ? gestureGreaterThan : gestureLessThan;
Log.d("DEBUG", "Gesture: " + gesture);

\end{lstlisting}

%% Notifications
\section{Notifications}

Notifications are a key part of Android Wear as they are not applications which
need to be launched by the user. They are a way of displaying small glanceable
information to the user that can have certain quick-actions such as replying
to a text message, or opening an application on the handheld in order to
complete a larger action. Notifications are at the heart of what Android Wear
is designed for and are easily created and displayed using the Android APIs.

By default, a notification built for a handheld application will display on
Android Wear without any modifications. They can however be "extended" to show
information that would be displayed specifically for wearable devices.

\begin{lstlisting}[language=Java]

// the intent to start when the notification is clicked
Intent intent = new Intent(this, TimetableActivity.class);

// build the notification
NotificationCompat.Builder notificationBuilder =
        new NotificationCompat.Builder(this)
        .setSmallIcon(R.drawable.ic_notif)
        .setContentTitle("Sample Notification")
        .setContentText("This is a sample notification")
        .setContentIntent(viewPendingIntent);

// get an instance of the NotificationManager service
NotificationManagerCompat notificationManager =
        NotificationManagerCompat.from(this);

notificationManager.notify(notificationId, notificationBuilder.build());

\end{lstlisting}

The code listing above describes how to build a notification that can be
displayed on a handheld device. By default, this notification will also get
displayed on the wearable. In order to add wearable specific-features to the
notification, we use a \texttt{WearableExtender}:

\begin{lstlisting}[language=Java]

// Create a WearableExtender to add functionality for wearables
NotificationCompat.WearableExtender wearableExtender =
        new NotificationCompat.WearableExtender()
        .setBackground(mBitmap);

// extend the notification with the wearable-specific features
notificationBuilder.extend(wearableExtender);

// display the notification
notificationManager.notify(notificationId, notificationBuilder.build());

\end{lstlisting}

Here we can set the background of the notification which will be displayed on
the wearable. This background will not get displayed on any handheld devices.
By default adding actions to the notification will also work on the wearable,
but sometimes it is desirable to show certain actions only on the wearable, such
as "Open on phone". This action should not be displayed in the notification of
the phone itself. This can be accomplished by using the \texttt{extend()} method
of the \texttt{NotificationBuilder}

\begin{lstlisting}[language=Java]

new NotificationCompat.Builder(mContext)
        .setSmallIcon(R.drawable.ic_message)
        .setContentTitle(getString(R.string.title))
        .setContentText(getString(R.string.content))

        // add wearable only actions
        .extend(new WearableExtender().addAction(action));

\end{lstlisting}

%% STUDENT APP

\section{Student Application}

The following section will describe the implementation of the Student
Application for handheld devices and it's wearable counterpart app. The handheld
app consists of a main menu (shown in Figure \ref{fig:handheld_main_menu}) which displays all the
available sections of the app.

The handheld application uses SQLite for it's database, and uses the open source
Sugar ORM\footnote{Sugar ORM: http://satyan.github.io/sugar/} for it's
Object-Relational mapping capabilities. This allows much easier storage of Java
objects in a relational database and Sugar ORM provides much of the database
boilerplate code through the use of Reflection.

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{mobile-main-screen.png}
    \caption{Handheld main menu}
    \label{fig:handheld_main_menu}
\end{figure}

The sections of the app are as follows:
\begin{enumerate}
\item Modules\\
    This screen allows the user to manage their modules or subjects for
    college. They can add or remove different modules which are then used by
    other screens within the app.
\item To-do list\\
    The user can create reminders and to-do items in this screen. To-do items
    can be created, removed or marked as completed. These to-do items are also
    synced across to the wearable where they can be viewed and marked as
    complete.
\item Timetable\\
    In this screen, the user can view their timetable. Lectures are created on
    this screen and contain a title, room, day and time.
\item Results\\
    Results for each module are displayed on this screen and new results can be
    added or removed in sub screens.
\item News\\
    This screen displays the recent news from the UCC website
    \footnote{UCC News page: http://www.ucc.ie/en/about/uccnews/} in the form
    of a native Android list, the articles are shown when the article image or
    headline is clicked by the user.
\item Campus Map\\
    This section is only contained on the wearable app and is designed to have
    the coordinates of the UCC campus preloaded onto the handheld, which then
    downloads images of the map from Google Maps and displays them on the
    wearable in case the user is lost on campus.
\item Games\\
    This section contains only one game on the handheld, and that is a game of
    Snake. The Snake game is played using wearables or other mobile devices as
    controllers and is played over Bluetooth.
\end{enumerate}

\subsection{Modules}
When the user creates a new module, a \texttt{Module} object is created. This
\texttt{Module} instance is also \texttt{Parcelable}. The new instance is stored
in the handheld device's SQLite database. All modules in this database are then
read into a \texttt{List}, parceled up, and synced to the wearable device.

In order to sync the whole list over to the weearable, the objects in the list
must implement \texttt{Parcelable}. Once the list is put into the data layer of
Android Wear, the wearable can read and display the list of modules by calling
\texttt{Wearable.DataApi.getDataItems} and filtering by the path of the modules
which in this case is \texttt{"/modules/get"}.

Although using this method to synchronize the modules to the wearable works,
and works quite quickly as the module objects are small in sie and quick to
transfer. It is not the most optimal method for syncing the modules. A better
approach woould be to implement a database on the wearable device as well as the
handheld and only put the new module object into the data layer when it is
created. This means that only one module object would be transfered when a new
module is created rather than the entire list.

However, using this method would require a database on both sides of the
connection, and would also require the wearable application to be running a
\texttt{WearableListenerService} to be able to spot the changes to the data
layer when the wearable app is not in the foreground. This is a lot of extra
complexity for a list of modules, that realistically should never reach over
10-15 modules. If the dataset was much larger, the more efficient solution
would be a far better approach and would be a noticeably better user experience.

\subsection{To-Do List}
The to-do list is implemented rather similarly to the Modules screen. The major
difference between the screens is that to-do list items can be created on the
wearable device as well as the handheld. This means that while the application
is in the foreground on the handheld, the dataset might change after it has been
retrieved from the database.

\subsubsection{Creating items on the wearable}
Creating to-do items on the handheld is straight-forward. An \texttt{EditText}
is used to get the title of the to-do item and it is stored in the database.
However, since the wearable's screen is too small to house a full-blown
keyboard, another form of input must be used.

The only alternate way of getting textual input from the user on a wearable is
to use the user's voice as input. Android Wear comes with APIs for doing exactly
that. The wearable uses a \texttt{SpeechRecognizer} activity which listens for
the user's voice and returns the speech data to the calling Activity.

\begin{lstlisting}[language=Java]

// Create an intent that can start the Speech Recognizer activity
private void displaySpeechRecognizer() {
    Intent intent = new Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH);
    intent.putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL,
            RecognizerIntent.LANGUAGE_MODEL_FREE_FORM);
    // Start the activity, the intent will be populated with the speech text
    startActivityForResult(intent, SPEECH_REQUEST_CODE);
}

\end{lstlisting}

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{wearable-speech-recognizer.png}
    \caption{SpeechRecognizer Activity}
    \label{fig:speech_recognizer_activity}
\end{figure}

Calling \texttt{displaySpeechRecognizer()} above will start a system Activity
(Figure \ref{fig:speech_recognizer_activity})
which will display a screen which reads "Speak now". This screen will wait for
the user to speak, display the text it has heard, or "Sorry, didn't catch that".
This text is then returned to the calling Activity for processing.

In order to create a module from this text, we must override the
\texttt{onActivityResult()} method of the Activity. This is achieved as
follows:

\begin{lstlisting}[language=Java]

// This callback is invoked when the Speech Recognizer returns.
@Override
protected void onActivityResult(int requestCode, int resultCode,
                                Intent data) {
    if (requestCode == SPEECH_REQUEST_CODE && resultCode == RESULT_OK) {
        List<String> results = data.getStringArrayListExtra(
                RecognizerIntent.EXTRA_RESULTS);
        String spokenText = results.get(0);

        // only create a new item if the string is non-empty
        if (spokenText.length() > 0) {
            ToDoItem item = new ToDoItem(spokenText);
            syncToDoItem(item);
        }
    }
    super.onActivityResult(requestCode, resultCode, data);
}

\end{lstlisting}

\subsubsection{Syncing the items}

When a new to-do list item is created on the handheld, it is stored in the
database and synced to the wearable in the same way as a module is synced in
the previous section. This means that the wearable can access the entire list
of to-do items from the Android Wear data layer. However, if the user creates
a new to-do item on the wearable, the wearable stores the new to-do item in the
data layer at a different path. The handheld needs to be able to see this change
and store the new to-do item in it's database. This is made possible by the
\texttt{WearableListenerService} implemented on the handheld. When data is
changed in the data layer by the wearable, its \texttt{onDataChanged()} method
is called and if the path matches the path of the new item created by the
wearable, it can read the item from the data layer and store it in the SQLite
database. It will also update the list of to-do items in the data layer so the
wearable, on subsequent calls to \texttt{Wearable.DataApi.getDataItems}, will
get the most recent list of to-do items, including the item that was just
created on the wearable.

To-do items are now synced between both devices, but if the user creates an
item on the wearable while the handheld application is in the foreground, we
want the handheld's user interface to update with the new item. This is an
unlikely use-case that the user would have both applications in the foreground,
but is definitely a possibility.\\
To solve this issue, the \texttt{Fragment} displaying the to-do items on the
handheld can implement \texttt{DataApi.DataListener} in order to spot changes
to the data layer. When the fragment spots a change on the path 
\texttt{"/todo/create"}, it can update its list's \texttt{Adapter} and refresh
the data displayed to the user.

This change was also applied to the wearable application as it is also possible
to create a to-do item on the handheld while the wearable app is in the
foreground. Once both sides have the change applied, the user can create to-do
items on either side of the connection with both apps in the foreground and see
the changes immediately on both UIs.

\subsection{Timetable}

The timetable screen displays the user's lectures for the week in the form of
tabbed lists. Each day is its own tab and displays the days lectures in order
of earliest first. New lectures can be created by pressing the Floating Action
Button in the bottom right corner. Only days that have lectures are displayed in
the timetable, that is if the user has not created lectures for Saturday and
Sunday, they will not appear on the screen.

Each lecture is stored in the SQLite database using Sugar ORM. Using Sugar ORM
is a very simple. In order for a Java object to be stored in the database using
Sugar ORM, it must extend \texttt{SugarOrm<T>} where \texttt{T} is the class
that will be stored. For example, the \texttt{Lecture} class looks something
like this:

\begin{lstlisting}[language=Java]

public class Lecture extends SugarRecord<Lecture> {

    private String name;

    // an empty constructor is required by Sugar ORM
    public Lecture() {}

}

\end{lstlisting}

In the above listing, name will be a column in the database and an instance will
automatically populate it in the database with it's value when it is stored
using Java Reflection. If the object contains data that should not be inserted
into the database upon storage, it can be ignored using the \texttt{@Ignore}
annotation. For example:

\begin{lstlisting}[language=Java]

private long id;

// ignore the password attribute
@Ignore
private String password;

private String title;

\end{lstlisting}

\texttt{Lecture} objects can now be stored by calling \texttt{lecture.save()}.
In order to retrieve lectures from the database using the ORM, we can use
\texttt{Lecture.findById(Lecture.class, id)} to find a particular lecture once
it's id is known, or \texttt{Lecture.findAll(Lecture.class)} to list all
lectures currently stored in the database.

The timetable screen is unique to the handheld device and does not have any
counterpart on the wearable. This is mainly down to the limited screen
real estate available on the wearable. Instead however, notifications are used
to display upcoming lectures. This is achieved using Android's
\texttt{AlarmManager} to schedule a task every 10 minutes to check the created
lectures and see if any are occuring within the next 15 minutes. If a lecture
is starting in this time, a notification is built and displayed on both the
handheld and wearable devices. When the notification is clicked, the timetable
Activity is opened.

\subsection{Results}
The results screen displays a list of the user's modules with an animated
progress bar showing their average result for each module. Clicking on a module
brings the user to a new screen which displays each result for that module in
reverse-chronological order. This screen also displays an animated graph of
each of the results so the user can see their progress at a glance.

The graph is a custom view which overrides the \texttt{onDraw()} method and uses
paths to create the shape of the graph. Each vertex of the graph is animated
from the 50\% mark and the animation is offset by the vertex's x position so
each vertex animation begins a few milliseconds after the previous vertex's
animation has begun.

This custom view was created in the \texttt{common} module so that the view
could be used on both the handheld and wearable device. The main reason for
the addition of this graph was to see how the wearable could handle custom views
and animations. The animations run smoothly and without problem on both devices.


\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{mobile-results.png}
    \caption{Custom Graph View on handheld}
    \label{fig:mobile_results}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{wearable-results.png}
    \caption{Custom Graph View on wearable}
    \label{fig:wearable_results}
\end{figure}

The animations were achieved using Android's \texttt{ValueAnimator} class. This
class enables us to animate particular values from a start value to an end
value. To animate the results, each vertex in the graph is set to show 50\% and
is then animated to it's actual value.

\begin{lstlisting}[language=Java]

public void animateValues() {
    mAnimations = new ArrayList<>();
    for (int i = 0; i < mValues.size(); i++) {
        final float value = mValues.get(i);
        final int index = i;
        ValueAnimator anim = ValueAnimator.ofFloat(.5f, value);

        // offset each animation by 100 ms
        anim.setStartDelay(500 + (100 * i));
        anim.setDuration(1500);

        // make each vertex start fast and slow down
        anim.setInterpolator(new DecelerateInterpolator(3f));
        anim.addUpdateListener(new ValueAnimator.AnimatorUpdateListener() {
            @Override
            public void onAnimationUpdate(ValueAnimator animation) {
                // update the value of the vertex
                mValues.set(index, (float) animation.getAnimatedValue());
                invalidate();
            }
        });

        // start each vertex at 50%
        mValues.set(i, .5f);

        anim.start();
        mAnimations.add(anim);
    }
}

\end{lstlisting}

In order for the wearable to get the results of a given module from the
handheld, it retrieves a list of results from the data store in the same way
as for the modules. The path for the results is
\texttt{"/results/get/<module-id>"} where module-id is the id of the module to
get the results of. When a new result is added on the handheld application, the
result is stored in the database using Sugar ORM. The application then reads all
results for that module into a \texttt{List} and stores that list in the data
layer with the path \texttt{"/results/get/3"} where 3 would be the id of the
module. The wearable can then access these lists of results by calling
\texttt{getDataItems()} and filtering on the same path.

As mentioned previously if the dataset is large, the entire list should not be
synced, just the items that have changed and should be stored on both sides of
connection.

%% News

\subsection{News}

The news screen first scrapes the UCC news page
\footnote{UCC News page: http://www.ucc.ie/en/about/uccnews/} by downloading it,
parsing it using the \texttt{JSoup} library to find the news article titles and
images. It then displays the articles in a list using the new
\texttt{RecyclerView} which was introduced to Android in Lollipop and is
designed as a more flexible and versatile \texttt{ListView}. It implements the
\texttt{View Holder} pattern, making it more efficient by recyling (hence the
name) views rather than inflating a new view from XML every time a new item
appears on screen. The \texttt{RecyclerView} also has the added benefit of using
\texttt{LayoutManager}s to decide where and how items should appear. This makes
it easy to switch from single column lists to multi-column lists or grids.

Each article appears as an image with a title on the news screen. When one of
the articles is clicked, a new screen is shown with the article's contents. To
achieve this, a webview is populated with the contents of the article. The app
downloads the articles web page, and parses the HTML for the \texttt{\#content}
container in the webpage. This way the UCC website itself is not shown, just
the contents of the article.

Android provides many ways of downloading content using Http requests. This
project uses the open source
Volley\footnote{Volley library: http://developer.android.com/training/volley/index.html}.
This library makes downloading things very easy, without having to worry about
closing connections, or configuration changes causing the Activity to restart.
Since Android does not allow network acticity on the main thread, network
requests must be made on a background thread. For this reason many applications
might use an \texttt{AsyncTask} to download content, but this may cause problems
when the user rotates the phone, restarting the Activity and causing the 
\texttt{AsyncTask} to get 'lost'. This could be fixed by wrapping the
\texttt{AsyncTask} in a \texttt{Fragment} and calling
\texttt{setRetainInstance(true)} on the fragment to prevent it from being
restarted by the containing Activity, but Volley can handle all of this for us.

Downloading the UCC news page looks as follows:
\begin{lstlisting}[language=Java]

public static final String BASE_URL = "http://www.ucc.ie";
public static final String ALL_ARTICLES_URL = BASE_URL + "/en/news/";

...

mArticleRequest = MyVolley.getInstance(mContext).add(new StringRequest(
        ALL_ARTICLES_URL, new Response.Listener<String>() {
    @Override
    public void onResponse(String response) {
        // this will get called when we get a successful response
        parseResponse(response);
    }
}, new Response.ErrorListener() {
    @Override
    public void onErrorResponse(VolleyError error) {
        // this gets called when an error is returned from Volley or
        // the server
        onError();
        Log.e("E", "Error downloading: " + ALL_ARTICLES_URL);
    }
}));

\end{lstlisting}

\texttt{MyVolley} is just a simple wrapper for Volley a \texttt{RequestQueue}.
It is a singleton class that returns a single \texttt{RequestQueue} when 
\texttt{getInstance()} is called. \texttt{RequestQueue} objects are used to
queue downloads using Volley.\\
Parsing the articles from the returned HTML response looks like this:

\begin{lstlisting}[language=Java]

ArrayList<Article> articles = new ArrayList<>();

// parse the document using Jsoup
Document doc = Jsoup.parse(response);

// using CSS selectors we can extract an array of the articles in HTML
Elements articleElements = doc.select(".article");

// loop through each HTML article and create a Java object and add it
// to the List
for (Element element : articleElements) {
    Article article = createArticle(element);
    if (article != null) {
        articles.add(article);
    }
}

\end{lstlisting}

This screen was designed in such a way so that any news source could be used to
populate the list of articles. A custom interface called \texttt{ArticleFetcher}
can be implemented and replace the \texttt{UccArticleFetcher} class to download
the articles from a different source. For example, a college could replace it
with a \texttt{ArticleFetcher} that fetched articles from an Rss feed. Or
implement the code to scrape their own website and populate the screen with
articles. The \texttt{ArticleFetcher} interface is defined below.

\begin{lstlisting}[language=Java]

public interface ArticleFetcher {

    // callback listener for when the articles are ready
    public interface Listener {
        // called when the articles are downloaded and ready to be displayed
        public void onArticlesReady(List<Article> articles);
    }

    // ask the ArticleFetcher to start downloading the articles
    public void fetchArticles(Listener callback);

    // stop the downloading of the articles
    public void cancel();

}

\end{lstlisting}

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{wearable-notification-open-on-phone.png}
    \caption{Open on phone action of notification}
    \label{fig:wearable_open_on_phone}
    \includegraphics[width=0.4\textwidth]{wearable-news-notification.png}
    \caption{New article notification with background image of article}
    \label{fig:wearable_news_notification}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=.6\textwidth]{mobile-news-screen.png}
    \caption{News screen with UCC articles}
    \label{fig:handheld_news_screen}
\end{figure}

Since the wearable is not able to download articles itself, and reading an
article would be difficult on such a small screen, a service is scheduled to
run in the background every 2 hours using the Android \texttt{AlarmManager}.
This service runs the \texttt{UccArticleFetcher} and downloads the articles
from the UCC news page. It checks each article title and stores the most recent
article's title in \texttt{SharedPreference}s. If the previously stored article
title is different to the one just downloaded, a notification is shown to the
user on both the handheld and wearable device. The wearable notifications
background is set to the image of the article
(Figure \ref{fig:wearable_news_notification}) and a specific action
(Figure \ref{fig:wearable_open_on_phone}) is shown
to the user which when clicked (or touched) it will open the particular article
on the user's handheld device.


%% Campus Map

\clearpage
\section{Campus Map}

This screen is only available on the wearable and was added in case the student
gets lost on campus and needs a quick glance at the map to get their bearings
back. The screen contains a custom view \texttt{BitmapRegionView} which was
created with the goal of displaying a region of a large bitmap which can be
scrolled around to view the whole bitmap. It works by creating a \texttt{Rect}
object as a source input from the bitmap, and moving this \texttt{Rect} object
around the bitmap and drawing the region to the screen. The scrolling is done
using a \texttt{GestureDetector} object and listening for the \texttt{onFling}
method to be triggered. This view allows a large map image to be displayed at
full quality on a small screen and allows the user to pan around the large image
at will.

Since the wearable is not able to connect to the internet, it must ask the
handheld device for the map image. It does so by using the \texttt{MessageApi}
to send a message requesting the map image. When the handheld receives this
request, it makes an API call to
\texttt{http://maps.google.com/maps/api/staticmap} endpoint. This endpoint
allows us to download a static image of a location by providing a latitude and
longitude of the location as parameters. Zoom and map size can also be
specified for more control over the downloaded image. This image is then synced
to the wearable using the \texttt{DataApi}. The wearable app then displays this
large image using the custom \texttt{BitmapRegionView} implemented for this
purpose.

Originally this screen used a \texttt{GridViewPager} to display the map bitmap.
This is a wearable specific view that gives us a grid of pages which can be
scrolled through both horizontally and vertically. Each page was displaying
a chunk of the bitmap, but this view, since designed for wearables, behaved
in an unfavourable way when scrolling vertically. In a grid, one might expect
that when scrolling vertically, the column number would stay the same and the
row number would change by 1. However with a \texttt{GridViewPager} the row
number resets to 0 when scrolling vertically, so it does not function exactly
how one might think a grid would function. For this reason the custom view
\texttt{BitmapRegionView} was created.

Since this Activity uses a \texttt{GestureListener} to detect swipes, the
system default of swiping from the left to go back to the previous screen was
negatively affecting swiping to see different parts of the map. Since this is
the default behaviour, it should only be overridden if unavoidable. Thankfully,
Android Wear has provided a second alternative way of closing a screen if the
back-gesture is not an option, and that is a long-press anywhere on the screen.
In order to implement this, the back-gesture must be disabled and the long-press
must be listened for in the Activity instead. In order to disable the
back-gesture, a rule must be secified in the style of that Activity.

\texttt{AndroidManifest.xml}
\begin{lstlisting}[language=XML]

<application ...>

    <!-- set a style on the Activity -->
    <activity
            android:name=".activities.MapActivity"
            android:theme="@style/NoSwipeBack" />

</application>

\end{lstlisting}

\texttt{styles.xml}
\begin{lstlisting}[language=XML]

<?xml version="1.0" encoding="utf-8"?>
<resources>
    <style name="NoSwipeBack" parent="Theme.Wearable">
        <!-- disable the back-gesture -->
        <item name="android:windowSwipeToDismiss">false</item>
    </style>
</resources>

\end{lstlisting}

Now that the back-gesture is disabled, the user has no way of leaving the
\texttt{MapActivity}. We must now implement the long-press gesture instead.
Android Wear has a built in view that can be displayed when a long-press has
occurred called \texttt{DismissOverlayView}. This view can display a message
when the Activity is first launched instructing the user about the long-press
to go back gesture. When the long-press occurs, it then dimisses the screen
automatically. In order to set the \texttt{MapActivity} uo to use this view, we
must create an instance of the view in the \texttt{onCreate} method and add
the view to our layout XML file.

\texttt{activity\_map.xml}
\begin{lstlisting}[language=XML]

<android.support.wearable.view.DismissOverlayView
        android:id="@+id/dismiss_overlay"
        android:layout_height="match_parent"
        android:layout_width="match_parent"/>

\end{lstlisting}

\texttt{MapActivity.java}
\begin{lstlisting}[language=Java]

// create the DismissOverlayView
mDismissOverlay = (DismissOverlayView) findViewById(R.id.dismiss_overlay);

// set the text that will be shown if the user has never been to
// this screen before
mDismissOverlay.setIntroText("Long press to exit");
mDismissOverlay.showIntroIfNecessary();


// add the long-press gesture to the BitmapRegionView
mBitmapRegionView.setLongClickListener(new View.OnLongClickListener() {
    @Override
    public boolean onLongClick(View v) {
        mDismissOverlay.show();
        return false;
    }
});

\end{lstlisting}

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{wearable-map.png}
    \caption{Map region shown on watch}
    \label{fig:wearable_map}
    \includegraphics[width=0.4\textwidth]{wearable-exit-activity.png}
    \caption{DismissOverlayView with long-press gesture}
    \label{fig:wearable_dismiss_overlay}
\end{figure}

Now when the user first enters the screen, they will be presented with a pop-up
describing how to exit the Activity. When they long-press the
\texttt{BitmapRegionView}, they will be presented with another pop up with a
large 'X' as shown in figure \ref{fig:wearable_dismiss_overlay} which when
clicked will perform the equivalent of the back-gesture we disabled.


%% Games

\clearpage
\section{Games}

As part of the student application, a few games were developed and designed to
be short and simple to play. The following games were developed as part of the
student appliction:\\
Wearable:
\begin{enumerate}
\item Lights Out\\
    A puzzle game where the user is presented with a grid of lights, some of
    which are in the on state. The goal is to turn off all the lights by
    clicking them, but when turning off a light, that light's neighbours are
    turned on.
\item Minesweeper\\
    A puzzle game where the player must locate a given number of mines in a
    grid of squares. Squares that do not contain a mine display the number of
    adjacent squares which do contain mines. The goal is to flag all the mines
    by analyzing the numbers and not clicking any square with a mine.
\item Game Controller\\
    Not a game, but a controller that sends bluetooth commands for up, down,
    left and right. Used for the multiplayer game of snake on the handheld, but
    could be used by any Bluetooth game that implements the protocol.
\end{enumerate}

Handheld:
\begin{enumerate}
\item Multiplayer Snake\\
    A game of Snake similar to the snake game preloaded on Nokia phone in 1998
    with Bluetooth multiplayer where each player controls a different snake and
    the aim is to be the last snake that hasn't crashed.
\end{enumerate}


\subsection{Lights Out}

Lights Out
\footnote{Lights Out Wikipedia: http://en.wikipedia.org/wiki/Lights\_Out\_\%28game\%29}
(Figure \ref{fig:lights_out_game})
is a puzzle game where the goal is to turn off all lights on the screen. It is
a grid based game and so was a perfect fit for the square screen of the watch.
However, on a circular watch screen the game is un-playable as the squares in
the corners are truncated of screen and so cannot be clicked.

The game was implemented using a Model View Controller (MVC) approach. The
model is a simple \texttt{Tile} class consisting of the tile's position and
state. The view is a canvas-based custom view that displays the grid and the
tiles contained within the grid. And finally the controller is the 
\texttt{LightsOutController} class which controls the access to the models,
and translates input into actions on the view and state of the game.

This MVC pattern allows us to swap out any part for a different implementation.
The low coupling between the controller and the view allows us to change the
view from being canvas-based to an XML layout of buttons and images for example
with little to no code changes.

The game controller keeps track of an array of tiles which form the grid. Each
tile has a position and state: on or off. When starting the game a level can
be selected from the menu. Levels are stored as strings in the form "OOXOO...".
These strings are processed character by character moving over the grid square
by square. The first character of the level string is applied to the first
square in the grid, the second character on the second square etc.\\
An "O" character means skip this square, a "X" means click this square. The
controller processes each character until the game has been initialized with
some lights, which the player has to reverse. The benefit of creating levels in
such a way, is that we know the optimal number of moves needed in order to
complete the level, that is, reverse the moves performed by the initialization
of the level string. Using this optimal number of moves we can then keep track
of the number of moves the player makes and calculate a score based on some
algorithm.

Due to the small size of the wearable screen, we are limited in the number of
tiles we can display in the grid whilst still keeping the tiles large enough
for the player to click without accidentally clicking the wrong tile. As a
result levels are limited in complexity and size to about 5x5 grids.

In the implementation of the game, the Activity is used as a middle man between
the controller and the view. The Activity is responsible for taking input from
the user and passing the information to the controller. The Activity is also
a registered listener of the controller and can update the view using the
defined callback methods specified by the \texttt{LightsOutController\$Listener}
interface shown below. In this way, the Activity acts as the glue between the
view and the controller.

\begin{lstlisting}[language=Java]

// interface defined within the LightsOutController class
public interface Listener {
    // called when a tile was clicked
    public void onTileToggled(Tile tile);

    // called when all lights have been turned off
    public void onGameOver(int numMoves);
}

\end{lstlisting}

When a level is complete, the score is calculated and a success view is shown
to the user displaying their score. This view is a \texttt{ConfirmationActivity}
(Figure \ref{fig:success_screen})
which is a built-in Android Wear Activity designed for showing the user a quick
message that dismisses itself quickly. It is the recommended way of showing the
user quick information that an action has been complete, without distracting
them too much from their current task.

\subsection{Minesweeper}

Minesweeper\footnote{Minesweeper Wikipedia: http://en.wikipedia.org/wiki/Minesweeper\_\%28video\_game\%29}
(Figure \ref{fig:minesweeper}) is a puzzle game where the objective is to clean
a mine field by flagging the mines. It is a grid based game where a given amount
of mines are scattered across the grid randomly and it is up to the player to
click on all squares apart from the ones containing mines. To help the player
achieve this, squares that do not contain mines display how many neighbouring
squares contain mines when clicked. Using these numbers, the player must decide
which squares to click and which squares to flag as mines. The game is over when
the player clears all non-mine squares or clicks a square containing a mine, in
which case the game is lost.

The game is built similarly to Lights Out in that it is grid based and contains
tiles. It also uses the MVC pattern explained above, but in this case an Android
layout is used instead of a canvas-based custom view. This layout contains a
single root \texttt{LinearLayout} element which is populated by other 
\texttt{LinearLayout}s at runtime, depending on how many rows are specified by
the controller. These \texttt{LinearLayouts} are then populated with custom
buttons which extend the android \texttt{Button} class depending on how many
columns the controller has specified. This allows the layout to be just as
dynamic as the canvas-based view used for Lights Out, but with the added benefit
of being aple to handle input/clicks for each individual button in the grid,
rather than having to figure out where the player clicked and decide which
button was hit.

\texttt{activity\_grid.xml}:
\begin{lstlisting}[language=Java]

<?xml version="1.0" encoding="utf-8"?>

<LinearLayout xmlns:android="http://schemas.android.com/apk/res/android"
    android:id="@+id/grid_layout"
    android:layout_width="match_parent"
    android:layout_height="match_parent"
    android:orientation="vertical">

</LinearLayout>

\end{lstlisting}

It does however increase complexity, and adding views at runtime is more
error-prone than creating the views at compile time in XML where a GUI can be
used to preview what the layout will eventually look like. For describing how
views should be layed out programmatically in Android, \texttt{LayoutParams}
must be used and can be cumbersome and verbose. The rows and buttons are added
to the grid as follows:

\begin{lstlisting}[language=Java]

// setup the minesweeper grid view
// here rootView is the root LinearLayout
private void setupView(LinearLayout rootView) {

    // the layout params for the buttons
    LinearLayout.LayoutParams buttonParams = new LinearLayout.LayoutParams(
            LinearLayout.LayoutParams.MATCH_PARENT,
            LinearLayout.LayoutParams.MATCH_PARENT, 1.0f);

    // add a new view for each row
    for (int y = 0; y < mRows; y++) {

        // layout params for the row views
        LinearLayout.LayoutParams rowParams = new LinearLayout.LayoutParams(
                LinearLayout.LayoutParams.MATCH_PARENT,
                LinearLayout.LayoutParams.MATCH_PARENT, 1.0f);

        // the row view itself
        LinearLayout rowLayout = new LinearLayout(getApplicationContext());
        rowLayout.setOrientation(LinearLayout.HORIZONTAL);
        rowLayout.setLayoutParams(rowParams);

        // create the buttons for each row
        for (int x = 0; x < mCols; x++) {

            // create the button
            GridButton button = createButton(x, y);
            button.setOnClickListener(mButtonClickListener);
            button.setLayoutParams(buttonParams);

            // callback for the controller
            onButtonCreated(button);
            
            // add the button to the row view
            mGrid[x][y] = button;
            rowLayout.addView(button);
        }

        // add the row to the grid
        rootView.addView(rowLayout);
    }
}

\end{lstlisting}

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{wearable-lights-out.png}
    \caption{Lights Out game}
    \label{fig:lights_out_game}
    \includegraphics[width=0.4\textwidth]{wearable-minesweeper.png}
    \caption{Minesweeper}
    \label{fig:minesweeper}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{wearable-success-screen.png}
    \caption{Success Screen}
    \label{fig:success_screen}
\end{figure}


\clearpage
\subsection{Multiplayer Snake}

The final game developed for this project was a game of Multiplayer
Snake\footnote{Snake Wikipedia: http://en.wikipedia.org/wiki/Snake\_\%28video\_game\%29}.
The game is played over Bluetooth with one handheld acting as the game's screen
while the wearables/other handhelds act as the controllers. The game can be
played with 1-7 players as Bluetooth has a limit on how many devices can be
connected at one time. This limit, however can be raised to 255 by using a
Piconet\footnote{http://en.wikipedia.org/wiki/Piconet}.

A Piconet consists of one master device, the screen/handheld device in this case
and up to seven slave devices, the controllers in this case. To raise the seven
slave device limit, slaves can be set in "parked" mode where they are inactive
but still part of the Piconet. We could swap devices in and out of parked mode
to give the appearance that all devices are active, when in actual fact only
seven are active at any one time. As a result we could connect up to 255 slave
or controller devices. However, having 255 players in a game of Snake would not
be playable!

The objective of this version of Snake, is to be the last player alive. Each
player controls a different snake, and must eat the food (a red square) in order
to make their snake longer. A snake dies when it's head collides with it's own
or another snakes body. Longer snakes can try and trap other snakes by boxing
them in. The winner is the last snake that has not crashed.

This game uses raw Bluetooth sockets as Android Wear does not allow multiple
wearables to connect to a single handheld device. The connection is one-to-one
which means that one handheld cannot have multiple wearables and vice-versa.
Due to this limitation, raw Bluetooth sockets were used. Google advises against
doing this, but as a multiplayer game cannot be multiplayer with only one
controller device, a workaround had to be implemented.

As a result of not using Android Wear APIs for the game, a protocol had to be
invented for the controllers to communicate with the master device. The master
device waits for controllers to connect. When a controller wants to connect, it
uses the pre-defined \texttt{uuid} of the master device to create a
\texttt{BluetoothSocket} for the master. The master creates a separate thread
for each controller it connects to. Each thread has a unique identifier which
it uses to differentiate which player sent which message.

\subsubsection{Bluetooth Controller Protocol}

The controllers can send the following messages on their
\texttt{BluetoothSockets} to have the following effects on that player's snake.

\begin{lstlisting}[language=Java]
"left"      => move the snake left
"right"     => move the snake right
"up"        => move the snake up
"down"      => move the snake down

\end{lstlisting}



%% Watchface

\section{Custom Watchface}

The final part of the project was the implementation of a custom watchface using
the official Android Wear APIs. At the beginning of the project, these APIs were
not finalized nor made made publicly available, so an attempt was made to use
whatever made the watchface work. A decent attempt was made, but did not follow
the guidelines which were later released, and so the code was updated to follow
these
guidelines\footnote{ttps://developer.android.com/design/wear/watchfaces.html}
and use the officially released APIs instead.

\subsection{Overview}

A custom watchface, is a service that runs constantly on the wearable. It is the
equivalent of the homescreen on a handheld device as it is the first thing the
user sees when the device is woken. A watchface has the added benefit of also
being able to display things on screen when the device is not woken, but in a
low-power mode so the user can constantly see the time. This mode is called
"Ambient Mode" and is triggered when the user is no longer interacting with the
watch. In Ambient mode, the watchface should be wary of saving power. As such,
it should only update the display when necessary and should avoid displaying
too much colour or white pixels in order to avoid pixel burn-in.

A watchface cannot handle input as it is the screen used by the system to carry
out system-default functions, such as launching an app or pulling down the
quick settings toggles. Overriding these functions would be discouraged and
confusing for the user.

Watchfaces use two extra permissions, which must be declared in the
\texttt{AndroidManifest.xml} file. These permissions are used because the
watchface needs to be able to run in the background and keep the processor
active to execute it's code.

\begin{lstlisting}[language=Java]

<manifest ...>

    <!-- watchface permission -->
    <uses-permission
        android:name="com.google.android.permission.PROVIDE_BACKGROUND" />

    <!-- permission to wake the processor when device is not active -->
    <uses-permission
        android:name="android.permission.WAKE_LOCK" />
    ...
</manifest>

\end{lstlisting}

\subsection{Watchface API}

Android Wear provides a Service class which can be extended to create a
watchface. This class is a very barebones implementation, and the
programmer is left to implement much of the boilerplate code. An easier class
to extend is the \texttt{CanvasWatchFaceService} which is also provided by
Android Wear, but gives the programmer access to a \texttt{Canvas} object which
can be drawn to for easy displaying of graphics. Other wise OpenGL would have
to be used, which is a more powerful graphics API than canvas, but also has
much steeper learning curve as it is much lower level.

The \texttt{CanvasWatchFaceService} looks as follows:
\begin{lstlisting}[language=Java]

public class AnalogWatchFaceService extends CanvasWatchFaceService {

    @Override
    public Engine onCreateEngine() {
        // the Engine is the class that will handle all watch-related tasks
        // and will also handle rendering to the screen
        return new Engine();
    }

    /* implement service callback methods */
    private class Engine extends CanvasWatchFaceService.Engine {

        @Override
        public void onCreate(SurfaceHolder holder) {
            super.onCreate(holder);
            // called when the Engine is created
        }

        @Override
        public void onPropertiesChanged(Bundle properties) {
            super.onPropertiesChanged(properties);
            // called when the properties of the watchface have been altered
        }

        @Override
        public void onTimeTick() {
            super.onTimeTick();
            // called every minute
        }

        @Override
        public void onAmbientModeChanged(boolean inAmbientMode) {
            super.onAmbientModeChanged(inAmbientMode);
            // called when the device goes in or out of Ambient Mode
        }

        @Override
        public void onDraw(Canvas canvas, Rect bounds) {
            // called when the Engine is invalidated
        }

        @Override
        public void onVisibilityChanged(boolean visible) {
            super.onVisibilityChanged(visible);
            // called when the watchface is no longer visible, ie. when the
            // user is in an app or the watchface is no longer in the
            // foreground
        }
    }
}

\end{lstlisting}

As you can see above, the system calls the \texttt{onTick} method every minute.
This may be enough when the device is in Ambient mode, but in order to show the
seconds hand on the clock, we will want to update the display every second while
not in Ambient mode. This must be implemented by the programmer, and this is how
it is done in the Calendar Watchface for this project:

\begin{lstlisting}[language=Java]

// delay in milliseconds
private static long TICK_DELAY = 1000;

private Handler mTimeTick;

// this task will be run every second
private final Runnable mSecondTick = new Runnable() {
    @Override
    public void run() {
        onSecondTick();
        if (isVisible() && !isInAmbientMode()) {
            mTimeTick.postDelayed(this, TICK_DELAY);
        }
    }
};

...

private void startTimer() {
    // cancel the current timer
    mTimeTick.removeCallbacks(mSecondTick);
    if (isVisible() && !isInAmbientMode()) {
        mTimeTick.post(mSecondTick);
    }
}

@Override
public void onCreate() {
    
    // start a task on the UI thread
    mTimeTick = new Handler(Looper.myLooper());
    startTimer();

}

public void onAmbientModeChanged(boolean inAmbientMode) {
    // reset the timer
    startTimer();
}

public void onSecondTick() {
    // code to be run every second
    if (isVisible() && !isInAmbientMode()) {
        invalidate();
    }
}

\end{lstlisting}

Here we use a \texttt{Handler} object to post \texttt{Runnable} objects to the
UI thread. In this case we are executing this runnable every second and
refreshing the display if the watchface is visible and not in Ambient mode.

\subsection{Drawing on the Canvas}

Drawing on the canvas is the same as drawing on a canvas for a custom view in
Android. \texttt{Paint} objects are used for stroking shapes in different styles
and colours. Detecting whether the screen is round or square is slightly
trickier than in a regular Android Wear app. In a normal app, a
\texttt{WatchViewStub} stub can be used to automatically apply a given layout
depending on the shape of the display as shown below:

\begin{lstlisting}[language=XML]

<android.support.wearable.view.WatchViewStub
    ...
    app:rectLayout="@layout/rect_activity_my_wear"
    app:roundLayout="@layout/round_activity_my_wear"
    ...
>

\end{lstlisting}

However, since the watchface is a service, it cannot inflate views to display on
screen. Instead, it must be done programatically. In order to achieve this, a
custom \texttt{WindowInsetsListener} must be created. This listener will be
given enough information to deterine the shape of the screen. This can be useful
for the application to know, so it can draw things on a particular region of the
canvas to endure that it is visible on all screen shapes. A custom listener is
shown below:

\begin{lstlisting}[language=Java]

view.setOnApplyWindowInsetsListener(new View.OnApplyWindowInsetsListener() {
    @Override
    public WindowInsets onApplyWindowInsets(View v, WindowInsets insets) {
        if (insets.isRound()) {
            // ROUND SCREEN
        } else {
            // SQUARE SCREEN
        }
        return insets;
    }
});

\end{lstlisting}

In order to draw text and shapes at certain locations on the watch, we must use
trigonometry to draw them at the correct locations on the canvas. For example,
in order to draw the numbers of a clock along the outside of the clock, sin and
cos must be used as follows:

\clearpage
\begin{lstlisting}[language=Java]

// incase we wanted a 24 hour clock
int numNumbers = 12;

mLength = // the radius of the clock

// start at 1 to have numNumbers at the top instead of 0
for (int i = 1; i <= numNumbers; i++) {
    float x, y;
    x = (float) Math.sin(Math.PI * 2 * (i / (float) numNumbers)) * mLength;
    y = - (float) Math.cos(Math.PI * 2 * (i / (float) numNumbers)) * mLength;
    canvas.drawText(String.format("%d", i),
        mCenter.x + x, mCenter.y + y,
        mPaint);
}

\end{lstlisting}

\subsection{Calendar Events}

The custom watchface developed for this project displays the user's calendar
events along the circumference of the watchface as long coloured arcs. Howevever
the wearable device does not directly have access to the handheld's calendar.
As a result there are two main ways to get the calendar events to the watch.
\begin{enumerate}
\item Manually\\
    Use the \texttt{MessageApi} to request the handheld to send the calendar
    events over to the wearable using the \texttt{DataApi} to store the objects.
\item WearableCalendarContract
    Use Android Wear's built in \texttt{WearableCalendarContract} to query the
    calendar directly from the wearable. This gives the programmer access to the
    \texttt{Cursor} instance with the results of the query.
\end{enumerate}

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{calendar-watchface.png}
    \caption{The custom Watchface in action}
    \label{fig:calendar_watchface}
\end{figure}

Combining the features described above, the custom watchface retrieves the
user's events from the handheld, wraps them into objects and displays them on
the canvas using the standard Canvas APIs. Figure \ref{fig:calendar_watchface}
depicts the final outcome.
